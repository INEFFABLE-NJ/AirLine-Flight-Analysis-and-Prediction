{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T18:10:39.973491Z",
     "start_time": "2024-11-22T18:10:39.965689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "ef7d9e0ab619291d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load dataset\n",
    "print(\"Loading dataset...\\n\\n\")\n",
    "train_data = pd.read_excel('Flight Dataset/Data_Train.xlsx')\n",
    "\n",
    "# Display initial rows and structure\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nDataset info:\")\n",
    "train_data.info()"
   ],
   "id": "50166d5ad9758f9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T18:10:44.190780Z",
     "start_time": "2024-11-22T18:10:44.166156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for null values\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(train_data.isnull().sum())"
   ],
   "id": "b089d3f13f81c898",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values:\n",
      "Airline            0\n",
      "Date_of_Journey    0\n",
      "Source             0\n",
      "Destination        0\n",
      "Route              1\n",
      "Dep_Time           0\n",
      "Arrival_Time       0\n",
      "Duration           0\n",
      "Total_Stops        1\n",
      "Additional_Info    0\n",
      "Price              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Drop missing values\n",
    "train_data.dropna(inplace=True)\n",
    "print(\"\\nDataset after dropping missing values:\")\n",
    "train_data.info()\n",
    "print(\"\\nFirst few rows after dropping missing values:\")\n",
    "print(train_data.head())"
   ],
   "id": "f59900cb892bc115"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Preserve original 'Airline', 'Source', 'Destination', and 'Price' for visualization\n",
    "airline_price_data = train_data[['Airline', 'Price']].copy()\n",
    "source_price_data = train_data[['Source', 'Price']].copy()\n",
    "destination_price_data = train_data[['Destination', 'Price']].copy()"
   ],
   "id": "152c69ea8868619"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Normalize 'New Delhi' in Source and Destination\n",
    "def normalize_city(city):\n",
    "    return \"Delhi\" if city == \"New Delhi\" else city\n",
    "\n",
    "train_data['Source'] = train_data['Source'].apply(normalize_city)\n",
    "train_data['Destination'] = train_data['Destination'].apply(normalize_city)\n",
    "print(\"\\nDataset after normalizing 'New Delhi':\")\n",
    "print(train_data.head())"
   ],
   "id": "6a7b552855fccc43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature extraction: Journey day and month\n",
    "train_data['Journey_day'] = pd.to_datetime(train_data['Date_of_Journey'], format='%d/%m/%Y').dt.day\n",
    "train_data['Journey_month'] = pd.to_datetime(train_data['Date_of_Journey'], format='%d/%m/%Y').dt.month\n",
    "train_data.drop('Date_of_Journey', axis=1, inplace=True)\n",
    "print(\"\\nDataset after extracting Journey_day and Journey_month:\")\n",
    "print(train_data.head())"
   ],
   "id": "c2c7458e0e3ff26e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Departure time (hour and minute)\n",
    "train_data['Dep_hour'] = pd.to_datetime(train_data['Dep_Time']).dt.hour\n",
    "train_data['Dep_min'] = pd.to_datetime(train_data['Dep_Time']).dt.minute\n",
    "train_data.drop('Dep_Time', axis=1, inplace=True)\n",
    "print(\"\\nDataset after extracting Dep_hour and Dep_min:\")\n",
    "print(train_data.head())"
   ],
   "id": "5785c936b223dff9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Arrival time (hour and minute)\n",
    "train_data['Arrival_hour'] = pd.to_datetime(train_data['Arrival_Time']).dt.hour\n",
    "train_data['Arrival_min'] = pd.to_datetime(train_data['Arrival_Time']).dt.minute\n",
    "train_data.drop('Arrival_Time', axis=1, inplace=True)\n",
    "print(\"\\nDataset after extracting Arrival_hour and Arrival_min:\")\n",
    "print(train_data.head())"
   ],
   "id": "362a8a55ac20ee90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Duration (hour and minute)\n",
    "print(\"\\nProcessing duration feature...\")\n",
    "duration = list(train_data['Duration'])\n",
    "for i in range(len(duration)):\n",
    "    if \"h\" not in duration[i]:\n",
    "        duration[i] = \"0h \" + duration[i]\n",
    "    if \"m\" not in duration[i]:\n",
    "        duration[i] += \" 0m\"\n",
    "\n",
    "train_data['Duration_hours'] = [int(d.split()[0][:-1]) for d in duration]\n",
    "train_data['Duration_mins'] = [int(d.split()[1][:-1]) for d in duration]\n",
    "train_data.drop('Duration', axis=1, inplace=True)\n",
    "print(\"\\nDataset after processing Duration:\")\n",
    "print(train_data.head())"
   ],
   "id": "1d48c24f357db78a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Replace Total_Stops with numerical values\n",
    "train_data['Total_Stops'] = train_data['Total_Stops'].replace({\n",
    "    'non-stop': 0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4\n",
    "})\n",
    "print(\"\\nDataset after encoding Total_Stops:\")\n",
    "print(train_data.head())"
   ],
   "id": "ade55e639e2c8e60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Categorical encoding\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "airline = pd.get_dummies(train_data['Airline'], drop_first=True)\n",
    "source = pd.get_dummies(train_data['Source'], drop_first=True)\n",
    "destination = pd.get_dummies(train_data['Destination'], drop_first=True)"
   ],
   "id": "78e85309ab087783"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Drop unnecessary columns\n",
    "train_data.drop(['Route', 'Additional_Info', 'Airline', 'Source', 'Destination'], axis=1, inplace=True)\n",
    "print(\"\\nDataset after dropping unnecessary columns:\")\n",
    "print(train_data.head())"
   ],
   "id": "85363bf765e5a06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Combine data with encoded features\n",
    "final_data = pd.concat([train_data, airline, source, destination], axis=1)\n",
    "print(\"\\nFinal dataset after combining with one-hot encoded variables:\")\n",
    "print(final_data.head())"
   ],
   "id": "9453fad9aa795a27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Splitting data into features and target\n",
    "X = final_data.drop('Price', axis=1)\n",
    "y = final_data['Price']"
   ],
   "id": "73248709d4691b73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualizations and analysis\n",
    "print(\"\\nAnalyzing the dataset with graphs...\")"
   ],
   "id": "b49a65337ee87855"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Airline price distribution using preserved data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Airline', y='Price', data=airline_price_data)\n",
    "plt.title('Airline vs Price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "id": "b2c5e0fcb0690602"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Source vs Price using preserved data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Source', y='Price', data=source_price_data)\n",
    "plt.title('Source vs Price')\n",
    "plt.show()"
   ],
   "id": "85741d54e68b4ade"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Destination vs Price using preserved data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Destination', y='Price', data=destination_price_data)\n",
    "plt.title('Destination vs Price')\n",
    "plt.show()"
   ],
   "id": "a43badad4bd241fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Heatmap for correlations\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(final_data.corr(), annot= False, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()"
   ],
   "id": "62b3b46983d2b67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature importance using ExtraTreesRegressor\n",
    "print(\"\\nEvaluating feature importance...\")\n",
    "extra_tree = ExtraTreesRegressor()\n",
    "extra_tree.fit(X, y)\n",
    "feature_importances = pd.Series(extra_tree.feature_importances_, index=X.columns)\n",
    "print(\"\\nTop 20 Feature Importances:\")\n",
    "print(feature_importances.nlargest(20))"
   ],
   "id": "fd2f4c655668d8a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importances.nlargest(20).plot(kind='barh')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.show()"
   ],
   "id": "e61306ee69b891a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Splitting dataset into training and testing sets\n",
    "print(\"\\nSplitting dataset into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(f\"Training data shape: {X_train.shape}, Test data shape: {X_test.shape}\")"
   ],
   "id": "c6b557caccc59463"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Hyperparameter tuning for Random Forest using RandomizedSearchCV\n",
    "print(\"\\nPerforming hyperparameter tuning for Random Forest...\")\n",
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=1200, num=12)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num=6)]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf, \n",
    "    param_distributions=random_grid, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    n_iter=10, \n",
    "    cv=5, \n",
    "    verbose=2, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")"
   ],
   "id": "629d8416739a6189"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train the model\n",
    "print(\"\\nTraining the Random Forest model with hyperparameter tuning...\")\n",
    "rf_random.fit(X_train, y_train)\n",
    "print(\"Best parameters for Random Forest:\", rf_random.best_params_)"
   ],
   "id": "91a327f172e1e417"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model evaluation\n",
    "print(\"\\nEvaluating the model...\")\n",
    "predictions = rf_random.predict(X_test)\n",
    "r2 = metrics.r2_score(y_test, predictions)\n",
    "print(f\"R2 Score: {r2}\")"
   ],
   "id": "c7257ceb8da8d19e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Residual plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(y_test - predictions, kde=True, bins=30)\n",
    "plt.title('Residual Distribution')\n",
    "plt.show()"
   ],
   "id": "dc74b3c55f8dc514"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Actual vs Predicted\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.5)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.show()"
   ],
   "id": "2e5291f78a636615"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T18:24:29.423155Z",
     "start_time": "2024-11-22T18:24:26.455794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "print(\"\\nSaving the model...\")\n",
    "with open('Trained_Model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_random, file)\n",
    "print(\"Model saved successfully as 'flight_rf.pkl'.\")"
   ],
   "id": "d5f116c8b7f86979",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the model...\n",
      "Model saved successfully as 'flight_rf.pkl'.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T18:25:01.820882Z",
     "start_time": "2024-11-22T18:25:00.628573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "model = pickle.load(open('Trained_Model.pkl', 'rb'))\n",
    "\n",
    "# Sample input data (you can modify these values for testing)\n",
    "dep_time = '2024-11-20T15:00'\n",
    "arrival_time = '2024-11-20T17:30'\n",
    "Total_stops = 1\n",
    "airline = 'IndiGo'\n",
    "Source = 'Delhi'\n",
    "Destination = 'Cochin'\n",
    "\n",
    "# Convert Dep_Time and Arrival_Time to relevant time features\n",
    "Journey_day = pd.to_datetime(dep_time, format=\"%Y-%m-%dT%H:%M\").day\n",
    "Journey_month = pd.to_datetime(dep_time, format=\"%Y-%m-%dT%H:%M\").month\n",
    "Departure_hour = pd.to_datetime(dep_time, format=\"%Y-%m-%dT%H:%M\").hour\n",
    "Departure_min = pd.to_datetime(dep_time, format=\"%Y-%m-%dT%H:%M\").minute\n",
    "\n",
    "Arrival_hour = pd.to_datetime(arrival_time, format=\"%Y-%m-%dT%H:%M\").hour\n",
    "Arrival_min = pd.to_datetime(arrival_time, format=\"%Y-%m-%dT%H:%M\").minute\n",
    "\n",
    "# Calculate duration\n",
    "dur_hour = abs(Arrival_hour - Departure_hour)\n",
    "dur_min = abs(Arrival_min - Departure_min)\n",
    "\n",
    "# Create dictionaries for airline, source, and destination\n",
    "airline_dict = {\n",
    "    'Jet Airways': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'IndiGo': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'Air India': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'Multiple carriers': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'SpiceJet': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'Vistara': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    'GoAir': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    'Multiple carriers Premium economy': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    'Jet Airways Business': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    'Vistara Premium economy': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    'Trujet': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "source_dict = {\n",
    "    'Delhi': [1, 0, 0, 0],\n",
    "    'Kolkata': [0, 1, 0, 0],\n",
    "    'Mumbai': [0, 0, 1, 0],\n",
    "    'Chennai': [0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "destination_dict = {\n",
    "    'Cochin': [1, 0, 0, 0],\n",
    "    'Delhi': [0, 1, 0, 0],\n",
    "    'Hyderabad': [0, 0, 1, 0],\n",
    "    'Kolkata': [0, 0, 0, 1],\n",
    "    'Banglore': [0, 0, 0, 0]  # Assuming Bangalore isn't mapped\n",
    "}\n",
    "\n",
    "# Get the airline, source, and destination values from the input\n",
    "airline_data = airline_dict.get(airline, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "source_data = source_dict.get(Source, [0, 0, 0, 0])\n",
    "destination_data = destination_dict.get(Destination, [0, 0, 0, 0])\n",
    "\n",
    "# Prepare the feature vector for prediction (X_test)\n",
    "X_test = [\n",
    "    Total_stops, Journey_day, Journey_month, Departure_hour, Departure_min,\n",
    "    Arrival_hour, Arrival_min, dur_hour, dur_min,\n",
    "    *airline_data, *source_data, *destination_data\n",
    "]\n",
    "\n",
    "# Test the model prediction\n",
    "output = model.predict([X_test])\n",
    "\n",
    "# Print the predicted price \n",
    "print(f\"Predicted Price: ₹{round(output[0], 2)}\")\n"
   ],
   "id": "1f1cb51dab959d21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price: ₹6441.79\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d78d1514740c315"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
